---
sidebar_position: 3
---

import {useTranslation} from 'react-i18next';

export default function LLMActionParsing() {
  const {i18n} = useTranslation();
  const isUrdu = i18n.language === 'ur';
  
  if (isUrdu) {
    return (
      <div>
        <h1>LLMs Ú©Û’ Ø³Ø§ØªÚ¾ Ø§Ø±Ø§Ø¯Û’ (Intent) Ú©Ùˆ Ø³Ù…Ø¬Ú¾Ù†Ø§</h1>
        
        <h2>ğŸ¯ LLMs Ú©ÛŒÙˆÚºØŸ</h2>
        
        <p>Ø±ÙˆØ§ÛŒØªÛŒ Ú†ÛŒÙ¹ Ø¨ÙˆÙ¹Ø³ Ø³Ø®Øª Ø§ØµÙˆÙ„ÙˆÚº (if/else) Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÛŒÚºÛ” <strong>Large Language Models (LLMs)</strong> Ø¬ÛŒØ³Û’ GPT-4 ÛŒØ§ Llama 3 Ù‚Ø¯Ø±ØªÛŒ Ø²Ø¨Ø§Ù† Ú©ÛŒ Ø¨Ø§Ø±ÛŒÚ©ÛŒÙˆÚº Ú©Ùˆ Ø³Ù…Ø¬Ú¾ Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ø±ÙˆØ¨ÙˆÙ¹Ú©Ø³ Ù…ÛŒÚºØŒ ÛÙ… Ø§Ù† Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ù…Ø¨ÛÙ… Ø§Ø­Ú©Ø§Ù…Ø§Øª ("Ù…Ø¬Ú¾Û’ Ú©Ú†Ú¾ Ù¾Ø§Ù†ÛŒ Ù„Ø§Ø¤") Ú©Ùˆ Ø³Ù¹Ø±Ú©Ú†Ø±Úˆ Ø§ÛŒÚ©Ø´Ù†Ø² (<code>navigate_to(kitchen), pick(water), navigate_to(user)</code>) Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ú©Ø±ØªÛ’ ÛÛŒÚºÛ”</p>
        
        <h2>ğŸ§  Ù¾Ø±Ø§Ù…Ù¾Ù¹ Ø§Ù†Ø¬ÛŒÙ†Ø¦Ø±Ù†Ú¯ (Prompt Engineering)</h2>
        
        <p>Ø±ÙˆØ¨ÙˆÙ¹ Ú©Ùˆ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ú©Ø±Ù†Û’ Ú©ÛŒ Ú©Ù„ÛŒØ¯ ØµØ­ÛŒØ­ Ù¾Ø±Ø§Ù…Ù¾Ù¹ ÛÛ’:</p>
        
        <pre>{`
You are a robot assistant. Your capabilities are:
1. move(direction, distance)
2. turn(angle)
3. pick(object)
4. place(location)

User Command: "Go to the kitchen and grab the apple."

Output JSON:
{
  "actions": [
    {"type": "move", "target": "kitchen"},
    {"type": "pick", "object": "apple"}
  ]
}
        `}</pre>
        
        <h2>ğŸ’» Python Ø§Ù†Ø¶Ù…Ø§Ù…</h2>
        
        <p>OpenAI API Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’:</p>
        
        <pre>{`
import openai
import json

def parse_command(command):
    prompt = f"""
    You are a robot. Convert this command to JSON actions:
    Command: "{command}"
    """
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return json.loads(response.choices[0].message.content)
        `}</pre>
        
        <h2>ğŸ”— LangChain Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„</h2>
        
        <p>Ù¾ÛŒÚ†ÛŒØ¯Û ÙˆØ±Ú© ÙÙ„Ùˆ Ú©Û’ Ù„ÛŒÛ’ØŒ <strong>LangChain</strong> Ø¨ÛØªØ±ÛŒÙ† ÛÛ’:</p>
        
        <pre>{`
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI(temperature=0)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a robot controller. Output JSON."),
    ("human", "{command}")
])

chain = prompt | llm
result = chain.invoke({"command": "Turn around and stop"})
        `}</pre>
        
        <h2>ğŸ›¡ï¸ Ø­ÙØ§Ø¸Øª Ø§ÙˆØ± ØªÙˆØ«ÛŒÙ‚</h2>
        
        <p>LLMs ØºÙ„Ø·ÛŒØ§Úº Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ” Ø¹Ù…Ù„ Ú©Ø±Ù†Û’ Ø³Û’ Ù¾ÛÙ„Û’ ÛÙ…ÛŒØ´Û Ø¢Ø¤Ù¹ Ù¾Ù¹ Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚ Ú©Ø±ÛŒÚº:</p>
        
        <ul>
          <li><strong>JSON Schema Validation</strong>: ÛŒÙ‚ÛŒÙ†ÛŒ Ø¨Ù†Ø§Ø¦ÛŒÚº Ú©Û Ø¢Ø¤Ù¹ Ù¾Ù¹ Ù…ØªÙˆÙ‚Ø¹ ÙØ§Ø±Ù…ÛŒÙ¹ Ø³Û’ Ù…ÛŒÙ„ Ú©Ú¾Ø§ØªØ§ ÛÛ’Û”</li>
          <li><strong>Safety Limits</strong>: Ø±ÙØªØ§Ø± Ø§ÙˆØ± Ù¹Ø§Ø±Ú© Ú©ÛŒ Ø­Ø¯ÙˆØ¯ Ú©Ùˆ Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”</li>
          <li><strong>Human in the Loop</strong>: Ø®Ø·Ø±Ù†Ø§Ú© Ú©Ø§Ø±Ø±ÙˆØ§Ø¦ÛŒÙˆÚº Ú©Û’ Ù„ÛŒÛ’ ØµØ§Ø±Ù Ø³Û’ ØªØµØ¯ÛŒÙ‚ Ø·Ù„Ø¨ Ú©Ø±ÛŒÚºÛ”</li>
        </ul>
        
        <h2>ğŸ“š Ø§Ú¯Ù„Û’ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª</h2>
        
        <p>Ø§Ø¨ ÛÙ…Ø§Ø±Û’ Ù¾Ø§Ø³ "Ú©Ø§Ù†" (Whisper) Ø§ÙˆØ± "Ø¯Ù…Ø§Øº" (LLM) ÛÛŒÚºÛ” Ø§Ú¯Ù„Ø§ØŒ <strong>Ù…Ú©Ù…Ù„ Ù¾Ø§Ø¦Ù¾ Ù„Ø§Ø¦Ù†</strong> Ø¨Ù†Ø§Ø¦ÛŒÚº â†’</p>
      </div>
    );
  }
  
  return (
    <div>
      <h1>Understanding Intent with LLMs</h1>
      
      <h2>ğŸ¯ Why LLMs?</h2>
      
      <p>Traditional chatbots use rigid rules (if/else). <strong>Large Language Models (LLMs)</strong> like GPT-4 or Llama 3 can understand natural language nuances. In robotics, we use them to convert vague commands ("Get me some water") into structured actions (<code>navigate_to(kitchen), pick(water), navigate_to(user)</code>).</p>
      
      <h2>ğŸ§  Prompt Engineering</h2>
      
      <p>The key to controlling robots is the right prompt:</p>
      
      <pre>{`
You are a robot assistant. Your capabilities are:
1. move(direction, distance)
2. turn(angle)
3. pick(object)
4. place(location)

User Command: "Go to the kitchen and grab the apple."

Output JSON:
{
  "actions": [
    {"type": "move", "target": "kitchen"},
    {"type": "pick", "object": "apple"}
  ]
}
      `}</pre>
      
      <h2>ğŸ’» Python Integration</h2>
      
      <p>Using OpenAI API:</p>
      
      <pre>{`
import openai
import json

def parse_command(command):
    prompt = f"""
    You are a robot. Convert this command to JSON actions:
    Command: "{command}"
    """
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return json.loads(response.choices[0].message.content)
      `}</pre>
      
      <h2>ğŸ”— Using LangChain</h2>
      
      <p>For complex workflows, <strong>LangChain</strong> is excellent:</p>
      
      <pre>{`
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

llm = ChatOpenAI(temperature=0)
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a robot controller. Output JSON."),
    ("human", "{command}")
])

chain = prompt | llm
result = chain.invoke({"command": "Turn around and stop"})
      `}</pre>
      
      <h2>ğŸ›¡ï¸ Safety and Validation</h2>
      
      <p>LLMs can make mistakes. Always validate output before execution:</p>
      
      <ul>
        <li><strong>JSON Schema Validation</strong>: Ensure output matches expected format.</li>
        <li><strong>Safety Limits</strong>: Check speed and torque limits.</li>
        <li><strong>Human in the Loop</strong>: Ask for confirmation for dangerous actions.</li>
      </ul>
      
      <h2>ğŸ“š Next Steps</h2>
      
      <p>Now we have "Ears" (Whisper) and "Brain" (LLM). Next, let's build the <strong>Complete Pipeline</strong> â†’</p>
    </div>
  );
}
